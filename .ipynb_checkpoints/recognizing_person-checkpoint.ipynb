{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading face detector...\n",
      "Loading face recognizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/altgate/anaconda3/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator SVC from version 0.23.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/altgate/anaconda3/lib/python3.9/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LabelEncoder from version 0.23.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "[ WARN:0] global /tmp/pip-req-build-3umofm98/opencv/modules/videoio/src/cap_v4l.cpp (890) open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting video stream...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     _, frame \u001b[38;5;241m=\u001b[39m cam\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m---> 32\u001b[0m     frame \u001b[38;5;241m=\u001b[39m \u001b[43mimutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     (h, w) \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     34\u001b[0m     imageBlob \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mdnn\u001b[38;5;241m.\u001b[39mblobFromImage(cv2\u001b[38;5;241m.\u001b[39mresize(frame, (\u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m300\u001b[39m)), \u001b[38;5;241m1.0\u001b[39m, (\u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m300\u001b[39m),(\u001b[38;5;241m104.0\u001b[39m, \u001b[38;5;241m177.0\u001b[39m, \u001b[38;5;241m123.0\u001b[39m), swapRB\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, crop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/imutils/convenience.py:69\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(image, width, height, inter)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresize\u001b[39m(image, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, height\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, inter\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mINTER_AREA):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# initialize the dimensions of the image to be resized and\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# grab the image size\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     (h, w) \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# if both the width and height are None, then return the\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# original image\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m width \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m height \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import imutils\n",
    "import pickle\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "embeddingModel = \"openface_nn4.small2.v1.t7\"\n",
    "\n",
    "embeddingFile = \"output/embeddings.pickle\"\n",
    "recognizerFile = \"output/recognizer.pickle\"\n",
    "labelEncFile = \"output/le.pickle\"\n",
    "conf = 0.5\n",
    "\n",
    "print(\"Loading face detector...\")\n",
    "prototxt = \"model/deploy.prototxt\"\n",
    "model = \"model/res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "detector = cv2.dnn.readNetFromCaffe(prototxt, model)\n",
    "\n",
    "print(\"Loading face recognizer...\")\n",
    "embedder = cv2.dnn.readNetFromTorch(embeddingModel)\n",
    "\n",
    "recognizer = pickle.loads(open(recognizerFile, \"rb\").read())\n",
    "le = pickle.loads(open(labelEncFile, \"rb\").read())\n",
    "\n",
    "box = []\n",
    "print(\"Starting video stream...\")\n",
    "cam = cv2.VideoCapture(0)\n",
    "time.sleep(2.0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    frame = imutils.resize(frame, width=600)\n",
    "    (h, w) = frame.shape[:2]\n",
    "    imageBlob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0, (300, 300),(104.0, 177.0, 123.0), swapRB=False, crop=False)\n",
    "\n",
    "    detector.setInput(imageBlob)\n",
    "    detections = detector.forward()\n",
    "\n",
    "    for i in range(0, detections.shape[2]):\n",
    "\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        if confidence > conf:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            face = frame[startY:endY, startX:endX]\n",
    "            (fH, fW) = face.shape[:2]\n",
    "\n",
    "            if fW < 20 or fH < 20:\n",
    "                continue\n",
    "\n",
    "            faceBlob = cv2.dnn.blobFromImage(face, 1.0 / 255, (96, 96), (0, 0, 0), swapRB=True, crop=False)\n",
    "            embedder.setInput(faceBlob)\n",
    "            vec = embedder.forward()\n",
    "\n",
    "            preds = recognizer.predict_proba(vec)[0]\n",
    "            j = np.argmax(preds)\n",
    "            proba = preds[j]\n",
    "            name = le.classes_[j]\n",
    "            text = \"{}  : {:.2f}%\".format(name, proba * 100)\n",
    "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY),(0, 0, 255), 2)\n",
    "            cv2.putText(frame, text, (startX, y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
